# Titles with very low cell counts to be combined to "rare" level
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
# Also reassign mlle, ms, and mme accordingly
full$Title[full$Title == 'Mlle']        <- 'Miss'
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales') # visualization
library('dplyr') # data manipulation
library('mice') # imputation
library('randomForest') # classification algorithm
train <- read.csv('./Data/train.csv', stringsAsFactors = F)
test  <- read.csv('./Data/test.csv', stringsAsFactors = F)
# 讀取資料
full  <- bind_rows(train, test)
# 合併資料
str(full)
# 印出資料
# Grab title from passenger names
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
# Show title counts by sex
table(full$Sex, full$Title)
# Titles with very low cell counts to be combined to "rare" level
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
# Also reassign mlle, ms, and mme accordingly
full$Title[full$Title == 'Mlle']        <- 'Miss'
full$Title[full$Title == 'Ms']          <- 'Miss'
full$Title[full$Title == 'Mme']         <- 'Mrs'
full$Title[full$Title %in% rare_title]  <- 'Rare Title'
# Show title counts by sex again
table(full$Sex, full$Title)
# Finally, grab surname from passenger name
full$Surname <- sapply(full$Name,
function(x) strsplit(x, split = '[,.]')[[1]][1])
full$Surname
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
install.packages("NLP")
install.packages("NLP")
install.packages("RCurl")
install.packages("XML")
install.packages("tm")
install.packages("tm")
source('~/GitHub/CSX_RProject_2018/week3/TFIDF/TFIDF_JapDrama.R')
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
# get the data from ptt: https://www.ptt.cc/bbs/marvel/index.html
from <- 2170
to <- 2178
prefix = "https://www.ptt.cc/bbs/marvel/index"
data <- list()
for( id in c(from:to)){
url <- paste0( prefix, as.character(id), ".html")
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@herf]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
data
source('~/GitHub/CSX_RProject_2018/week3/TFIDF/TFIDF_JapDrama.R')
getdoc <- function(url){
html <- htmlParse( getURL(url))
doc <- xpathSApply( html, "div[@id='main-content']", xmlValue )
temp <- gsub( " ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
# use the address to get the data
library(dplyr)
getdoc <- function(url){
html <- htmlParse( getURL(url))
doc <- xpathSApply( html, "div[@id='main-content']", xmlValue )
temp <- gsub( " ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
getdoc <- function(url){
html <- htmlParse( getURL(url))
doc <- xpathSApply( html, "div[@id='main-content']", xmlValue )
temp <- gsub( " ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
# clearfiy the data
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus,
function(word) {gsub("[A-Za-z0-9]", "", word)}
)
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
library(knitr)
kable(head(TDM))
install.packages("rattle",dependencies=c("Depends","Suggests"))
